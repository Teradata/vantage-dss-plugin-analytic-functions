{
  "json_schema_major_version": "1",
  "json_schema_minor_version": "2",
  "json_content_version": "1",
  "function_name": "TextClassifierTrainer",
  "function_version": "1.9",
  "function_type": "driver",
  "function_alias_name": "TextClassifierTrainer",
  "function_r_name": "aa.text.classifier.train",
  "short_description": "SQL/MR function for training a text classifier",
  "long_description": "The TextClassifierTrainer function trains a machine-learning classifier for text classification and installs the model file on the ML Engine. The model file can then be input to the function TextClassifier.",
  "input_tables": [
    {
      "requiredInputKind": [],
      "isOrdered": false,
      "partitionByOne": false,
      "name": "InputTable",
      "alternateNames": [],
      "isRequired": true,
      "rDescription": "Specifies the name of the table that contains the documents to use to train the model.",
      "description": "Specifies the name of the table that contains the documents to use to train the model.",
      "datatype": "TABLE_NAME",
      "allowsLists": false,
      "rName": "data",
      "useInR": true,
      "rOrderNum": 1
    }
  ],
  "argument_clauses": [
    {
      "targetTable": [
        "InputTable"
      ],
      "checkDuplicate": true,
      "allowedTypes": [],
      "allowedTypeGroups": [
        "ALL"
      ],
      "requiredLength": 1,
      "matchLengthOfArgument": "",
      "allowPadding": true,
      "name": "TextColumn",
      "alternateNames": [],
      "isRequired": true,
      "rDescription": "Specifies the name of the column that contains the text of the training documents.",
      "description": "Specify the name of the column that contains the text of the training documents.",
      "datatype": "COLUMN_NAMES",
      "allowsLists": false,
      "rName": "text.column",
      "useInR": true,
      "rOrderNum": 2
    },
    {
      "targetTable": [
        "InputTable"
      ],
      "checkDuplicate": true,
      "allowedTypes": [],
      "allowedTypeGroups": [
        "ALL"
      ],
      "requiredLength": 1,
      "matchLengthOfArgument": "",
      "allowPadding": true,
      "name": "CategoryColumn",
      "alternateNames": [],
      "isRequired": true,
      "rDescription": "Specifies the name of the column that contains the category of the training documents.",
      "description": "Specify the name of the column that contains the category of the training documents.",
      "datatype": "COLUMN_NAMES",
      "allowsLists": false,
      "rName": "category.column",
      "useInR": true,
      "rOrderNum": 3
    },
    {
      "permittedValues": [
        "maxEnt",
        "knn"
      ],
      "defaultValue": "maxEnt",
      "isOutputColumn": false,
      "name": "ClassifierType",
      "alternateNames": [],
      "isRequired": true,
      "rDescription": "Specifies the classifier type of the model, KNN algorithm or maximum entropy model.",
      "description": "Specify the classifier type of the model, KNN algorithm or maximum entropy model.",
      "datatype": "STRING",
      "allowsLists": false,
      "rName": "classifier.type",
      "useInR": true,
      "rOrderNum": 4
    },
    {
      "permittedValues": [],
      "isOutputColumn": false,
      "name": "ModelFile",
      "alternateNames": [],
      "isRequired": true,
      "rDescription": "The name of the model file to be generated.",
      "description": "Specify the name for the model file to create.",
      "datatype": "STRING",
      "allowsLists": false,
      "rName": "model.file",
      "useInR": true,
      "rOrderNum": 8
    },
    {
      "permittedValues": [],
      "isOutputColumn": false,
      "matchLengthOfArgument": "",
      "allowPadding": true,
      "name": "ClassifierParameters",
      "alternateNames": [],
      "isRequired": false,
      "rDescription": "Applies only if the classifier type of the model is KNN. Specifies parameters for the classifier. The name must be 'compress' and value must be in the range (0, 1). The n training documents are clustered into value*n groups (for example, if there are 100 training documents, then ClassifierParameters('compress:0.6') clusters them into 60 groups), and the model uses the center of each group as the feature vector.",
      "description": " Applies only if the classifier type of the model is KNN. Specify parameters for the classifier. The name must be 'compress' and value must be in the range (0, 1). The n training documents are clustered into value * n groups (for example, if there are 100 training documents, then ClassifierParameters('compress:0.6') clusters them into 60 groups), and the model uses the center of each group as the feature vector.",
      "datatype": "STRING",
      "allowsLists": true,
      "rName": "classifier.parameters",
      "useInR": true,
      "rOrderNum": 5
    },
    {
      "permittedValues": [],
      "isOutputColumn": false,
      "matchLengthOfArgument": "",
      "allowPadding": true,
      "name": "NlpParameters",
      "alternateNames": [],
      "isRequired": false,
      "rDescription": "Specifies natural language processing (NLP) parameters for preprocessing the text data and produce tokens. Each name:value pair must be one of the following:  tokenDictFile: token_file where token_file is the name of an Aster Database file in which each line contains a phrase, followed by a space, followed by the token for the phrase (and nothing else).  stopwordsFile:stopword_file where stopword_file is the name of an Aster Database file in which each line contains exactly one stop word (a word to ignore during tokenization, such as a, an, or the).  useStem:{true|false} which specifies whether the function stems the tokens. The default value is 'false'.  stemIgnoreFile:stem_ignore_file where stem_ignore_file is the name of an Aster Database file in which each line contains exactly one word to ignore during stemming. Specifying this parameter with 'useStem:false' causes an exception.  useBgram:{ true | false } which specifies whether the function uses Bigram, which considers the proximity of adjacent tokens when analyzing them. The default value is 'false'.  language:{ en | zh_CN | zh_TW } which specifies the language of the input text\u2014English (en), Simplified Chinese (zh_CN), or Traditional Chinese (zh_TW). The default value is en. For the values zh_CN and zh_TW, the function ignores the parameters useStem and stemIgnoreFile. Example: nlp.parameters ('tokenDictFile:token_dict.txt', 'stopwordsFile:fileName', 'useStem:true', 'stemIgnoreFile:fileName', 'useBgram:true', 'language:zh_CN')",
      "description": " Specify natural language processing (NLP) parameters for preprocessing the text data and produce tokens: name : value Description tokenDictFile: token_file token_file is name of ML Engine file in which each line contains a phrase, followed by a space, followed by the token for the phrase (and nothing else). stopwordsFile: stopword_file stopword_file is name of ML Engine file in which each line contains exactly one stop word (a word to ignore during tokenization, such as a , an , or the ). useStem:{ 'true' | 'false' } Specifies whether function stems tokens. Default: 'false' stemIgnoreFile: stem_ignore_file stem_ignore_file is name of ML Engine file in which each line contains exactly one word to ignore during stemming. Note: Specifying this parameter with useStem:'false' causes an exception. useBgram:{ 'true' | 'false' } Specifies whether function uses Bigram, which considers proximity of adjacent tokens when analyzing them. Default: 'false' language:{ 'en' | 'zh_CN' | 'zh_TW' } Specifies input text language\u2014English (Default), Simplified Chinese, or Traditional Chinese, respectively. Default: 'en' Note: For zh_CN and zh_TW , function ignores useStem and stemIgnoreFile . Example:",
      "datatype": "STRING",
      "allowsLists": true,
      "rName": "nlp.parameters",
      "useInR": true,
      "rOrderNum": 6
    },
    {
      "permittedValues": [],
      "isOutputColumn": false,
      "name": "FeatureSelectionMethod",
      "alternateNames": [],
      "isRequired": false,
      "rDescription": "Specifies the feature selection method, DF (document frequency). The values min and max must be in the range (0, 1). The function selects only the tokens that appear in at least min*n documents and at most max*n documents, where n is the number of training documents. For example, FeatureSelection ('DF:[0.1:0.9]') causes the function to select only the tokens that appear in at least 10% but no more than 90% of the training documents. If min exceeds max, the function uses min as max and max as min.",
      "description": " Specify the feature selection method, DF (document frequency). The values min and max must be in the range (0, 1). The function selects only the tokens that appear in at least min * n documents and at most max * n documents, where n is the number of training documents. For example, FeatureSelection\u00a0('DF:[0.1:0.9]') causes the function to select only the tokens that appear in at least 10% but no more than 90% of the training documents. If min exceeds max , the function uses min as max and max as min .",
      "datatype": "STRING",
      "allowsLists": false,
      "rName": "feature.selection",
      "useInR": true,
      "rOrderNum": 7
    },
    {
      "permittedValues": [],
      "isOutputColumn": false,
      "matchLengthOfArgument": "",
      "allowPadding": true,
      "name": "SequenceInputBy",
      "alternateNames": [],
      "isRequired": false,
      "rDescription": "Specifies the LIST_VECTOR of column(s) that uniquely identifies each row of the input argument INPUT_ARG_NAME. The argument is used to ensure deterministic results for functions which produce results that vary from run to run.",
      "description": "Specifies the input column(s) that uniquely identify each row of input table. The format is 'input1:c1' where input1 refers to the alias used by the input table that contains such column named c1.",
      "datatype": "STRING",
      "allowsLists": true,
      "rName": "sequence.column",
      "useInR": true,
      "rOrderNum": 50
    }
  ]
}